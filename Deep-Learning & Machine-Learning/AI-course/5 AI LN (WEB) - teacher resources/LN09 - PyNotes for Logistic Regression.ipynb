{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_regression #function used for generating synthetic datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "fruits = pd.read_csv('fruit_data_with_colors.txt', sep='\\t')\n",
    "fruits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_names_fruits = ['height', 'width', 'mass', 'color_score']\n",
    "\n",
    "X_fruits = fruits[feature_names_fruits]\n",
    "X_fruits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_fruits = fruits['fruit_label']\n",
    "y_fruits.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X_fruits, y_fruits, random_state = 0)\n",
    "\n",
    "#clf = LogisticRegression(C=100).fit(X_train, y_train) #alpha= 0=> overfit\n",
    "\n",
    "clftemp = LogisticRegression(C=100)\n",
    "\n",
    "clf = clftemp.fit(X_train, y_train) #alpha= 0=> overfit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we see too many coefficients here? There should be only one???\n",
    "\n",
    "### I will make it simpler. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I want to start with a simpler analysis. Hence I use only two of the features at first. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_fruits_2d = fruits[['height', 'width']] \n",
    "# or you can use the following\n",
    "#X_fruits_2d = fruits.loc[:, ['height', 'width']] # we use loc since this is a dataframe. \n",
    "\n",
    "y_fruits_2d = fruits['fruit_label']\n",
    "\n",
    "\n",
    "X_fruits_2d.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## I also convert the problem into a apple vs non-apple problem. That is normally, there are 4 different types of fruits in the dataset. I will change the labels of the apple to _True_ and the remaining ones are _False_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fruits_2d == 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "# I will convert the problem into apple vs not apple problem. \n",
    "\n",
    "y_fruits_apple = y_fruits_2d == 1   # make into a binary problem: apples vs everything else\n",
    "#y_fruits_apple = y_fruits_2d    # make into a binary problem: apples vs everything else\n",
    "\n",
    "y_fruits_apple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X_fruits_2d, y_fruits_apple, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=100).fit(X_train, y_train)\n",
    "\n",
    "print(\"The coefficients are\",clf.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Recall that the decision boundary for the logistic regression is the equation where the \n",
    "# theta0 + theta1 x1 + theta2 x2= 0. \n",
    "# Hence we need to find the equation of this line to plot it\n",
    "\n",
    "Plot_b0 = -clf.intercept_/clf.coef_[0,1] # -b/w2\n",
    "Plot_b1 = -clf.coef_[0,0]/clf.coef_[0,1] # -w1/w2\n",
    "\n",
    "# I will use them to plot the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.title('Sample regression problem with one input variable')\n",
    "\n",
    "X_fruits_2d_apple = X_fruits_2d[y_fruits_apple==True]\n",
    "X_fruits_2d_non_apple = X_fruits_2d[y_fruits_apple==False]\n",
    "\n",
    "\n",
    "plt.scatter(X_fruits_2d_apple.iloc[:,0], X_fruits_2d_apple.iloc[:,1], marker= 'o', s=50)\n",
    "plt.scatter(X_fruits_2d_non_apple.iloc[:,0], X_fruits_2d_non_apple.iloc[:,1], marker= 'x', s=50)\n",
    "plt.plot(X_fruits_2d_non_apple.iloc[:,0], Plot_b0 + Plot_b1 * X_fruits_2d_non_apple.iloc[:,0]  , 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or an easier way to plot the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "cmap_bold = ListedColormap(['#000000', '#FFFF00','#0000FF', '#00FF00' ])\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Sample binary classification problem with two informative features')\n",
    " \n",
    "plt.scatter(X_fruits_2d.iloc[:,0], X_fruits_2d.iloc[:,1], c=y_fruits_apple,\n",
    "           marker= 'o', s=50, cmap=cmap_bold)\n",
    "plt.plot(X_fruits_2d_non_apple.iloc[:,0], Plot_b0 + Plot_b1 * X_fruits_2d_non_apple.iloc[:,0]  , 'r-')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now I want to predict\n",
    "h = 6\n",
    "w = 6\n",
    "\n",
    "clf.predict([[h,w]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I want to predict\n",
    "h = 6\n",
    "w = 8\n",
    "clf.predict([[h,w]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# You can try  the following at home. \n",
    "## print([15,22][True])\n",
    "## print([15,22][False])\n",
    "## ['not an apple', 'an apple'][False]\n",
    "##['not an apple', 'an apple'][clf.predict([[h,w]])[0]]\n",
    "## print('A fruit with height {} and width {} is predicted to be: {}'\n",
    "   ##  .format(h,w, ['not an apple', 'an apple'][clf.predict([[h,w]])[0]]))\n",
    "    \n",
    "h = 10\n",
    "w = 7\n",
    "print('A fruit with height {} and width {} is predicted to be: {}'\n",
    "     .format(h,w, ['not an apple', 'an apple'][clf.predict([[h,w]])[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression on simple synthetic dataset\n",
    "\n",
    "#### First let's generate the data set. You can try it at home. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# synthetic dataset for classification (binary) \n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap_bold = ListedColormap(['#FFFF00', '#00FF00', '#0000FF','#000000'])\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Sample binary classification problem with two informative features')\n",
    "X_C2, y_C2 = make_classification(n_samples = 100, n_features=2,\n",
    "                                n_redundant=0, n_informative=2,\n",
    "                                n_clusters_per_class=1, flip_y = 0.1,\n",
    "                                class_sep = 0.5, random_state=0)\n",
    "plt.scatter(X_C2[:, 0], X_C2[:, 1], c=y_C2,\n",
    "           marker= 'o', s=50, cmap=cmap_bold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_C2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a91893f6d426>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_C2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_C2' is not defined"
     ]
    }
   ],
   "source": [
    "y_C2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I use the some of the built functions provided by the_Applied Machine Learning in Python_ course in Coursera.\n",
    "They have better plotting functions and they enable us to download some of the datasets that are provided only by coursera.\n",
    "You can use them if you wish but it's not a must."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import adspy_shared_utilities as asu\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X_C2, y_C2,random_state = 0)\n",
    "\n",
    "fig, subaxes = plt.subplots(1, 1, figsize=(7, 5))\n",
    "clf = LogisticRegression().fit(X_train, y_train) # by default it's one. \n",
    "title = 'Logistic regression, simple synthetic dataset C = {:.3f}'.format(1.0)\n",
    "asu.plot_class_regions_for_classifier_subplot(clf, X_train, y_train,\n",
    "                                         None, None, title, subaxes)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression with many classes. \n",
    "# BURADA KALDIm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a real dataset: Breast Cancer\n",
    "#### Try it at home. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "(X_cancer, y_cancer) = load_breast_cancer(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X_cancer)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer, random_state = 0)\n",
    "\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "print('Breast cancer dataset')\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use the scaling if you wish. \n",
    "#### Try it @ home. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "# we must apply the scaling to the test set that we computed for the training set\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test))\n",
    "\n",
    "X_test_scaled.head() #scaled version for 4 features. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
